+ Github license
+ Implement dictionary names
+ Nested elements for 'while find'
* Separate to page.get_name, search.get_price etc
* Create a data structure for returned data
* Learn to save the data to excel
* Learn how to not be identified as a bot

---

#### avoid scraper detector
request robots.txt <br>
- if contain crawl-delay 
    - set timeout to crawl-delay
- what to do if Disallow contain search? 
- is sitemap relevant to me? 
- "host" ?
>User-agent: * <br>
Disallow: <br> 
no restrictions
